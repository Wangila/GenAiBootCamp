{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "toc_visible": true,
      "name": "Day 3 - Building an agent with LangGraph",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wangila/GenAiBootCamp/blob/master/Day_3_Building_an_agent_with_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2025 Google LLC."
      ],
      "metadata": {
        "id": "b6e13eef3f5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "cellView": "form",
        "id": "d6597b11df14",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-01T07:59:55.528895Z",
          "iopub.execute_input": "2025-04-01T07:59:55.529312Z",
          "iopub.status.idle": "2025-04-01T07:59:55.534256Z",
          "shell.execute_reply.started": "2025-04-01T07:59:55.529274Z",
          "shell.execute_reply": "2025-04-01T07:59:55.533089Z"
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 3 - Building an agent with LangGraph and the Gemini API\n",
        "\n",
        "Welcome back to the Kaggle 5-day Generative AI course!\n",
        "\n",
        "In this notebook, you will use [LangGraph](https://www.langchain.com/langgraph) to define a stateful graph-based application built on top of the Gemini API.\n",
        "\n",
        "You will build a simulated cafe ordering system, called BaristaBot. It will provide a looping chat interface to customers where they can order cafe beverages using natural language, and you will build nodes to represent the cafe's live menu and the \"back room\" ordering system.\n",
        "\n",
        "BaristaBot is used in other Gemini API demos, so if you are looking to explore something with a more minimal implementation, check out the [BaristaBot function calling example](https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb) that implements a similar system using only the Gemini API Python SDK and function calling.\n",
        "\n",
        "## **IMPORTANT!**\n",
        "\n",
        "The app built in this notebook takes **user input** using a **text box** ([Python's `input`](https://docs.python.org/3/library/functions.html#input)). These are commented-out to ensure that you can use the `Run all` feature without interruption. Keep an eye out for the steps where you need to uncomment the `.invoke(...)` calls in order to interact with the app.\n",
        "\n",
        "If you wish to save a version of this notebook with `Save and Run all`, you will need to **re-comment** the lines you commented-out to ensure that the notebook can run without human input.\n",
        "\n",
        "## For help\n",
        "\n",
        "**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**"
      ],
      "metadata": {
        "id": "KDnGropl9aiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get set up\n",
        "\n",
        "Start by installing and importing the LangGraph SDK and LangChain support for the Gemini API."
      ],
      "metadata": {
        "id": "aKMOcAKnGBPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove conflicting packages from the Kaggle base environment.\n",
        "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
        "# Install langgraph and the packages used in this lab.\n",
        "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'"
      ],
      "metadata": {
        "id": "04fZ8d37ifOS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T03:20:49.381741Z",
          "iopub.execute_input": "2025-04-03T03:20:49.382305Z",
          "iopub.status.idle": "2025-04-03T03:21:36.896509Z",
          "shell.execute_reply.started": "2025-04-03T03:20:49.38226Z",
          "shell.execute_reply": "2025-04-03T03:21:36.894943Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f64ddd-6280-49c4-c004-9443c873e55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ydata-profiling as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTM_70ntysug",
        "outputId": "b677c8c0-27bc-4cbd-80cf-2f322caac0bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import gradio as gr\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "9hvldsCtyoSV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up your API key\n",
        "\n",
        "The `GOOGLE_API_KEY` environment variable can be set to automatically configure the underlying API. This works for both the official Gemini Python SDK and for LangChain/LangGraph.\n",
        "\n",
        "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
        "\n",
        "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
        "\n",
        "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
      ],
      "metadata": {
        "id": "GecNc73VGfpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "#GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "xaiioUQni_ga",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:20:49.056476Z",
          "iopub.execute_input": "2025-04-03T03:20:49.056932Z",
          "iopub.status.idle": "2025-04-03T03:20:49.379857Z",
          "shell.execute_reply.started": "2025-04-03T03:20:49.056871Z",
          "shell.execute_reply": "2025-04-03T03:20:49.378643Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n",
        "\n",
        "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
      ],
      "metadata": {
        "id": "e67a91692d36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key concepts\n",
        "\n",
        "LangGraph applications are built around a **graph** structure. As the developer, you define an application graph that models the state transitions for your application. Your app will define a **state** schema, and an instance of that schema is propagated through the graph.\n",
        "\n",
        "Each **node** in the graph represents an action or step that can be taken. Nodes will make changes to the state in some way through code that you define. These changes can be the result of invoking an LLM, by calling an API, or executing any logic that the node defines.\n",
        "\n",
        "Each **edge** in the graph represents a transition between states, defining the flow of the program. Edge transitions can be fixed, for example if you define a text-only chatbot where output is always displayed to a user, you may always transition from `chatbot -> user`. The transitions can also be conditional, allowing you to add branching (like an `if-else` statement) or looping (like `for` or `while` loops).\n",
        "\n",
        "LangGraph is highly extensible and provides a number of features that are not part of this tutorial, such as memory, persistance and streaming. To better understand the key concepts and philophies behind LangGraph, check out their [Conceptual guides](https://langchain-ai.github.io/langgraph/concepts/) and [High-level overview](https://langchain-ai.github.io/langgraph/concepts/high_level/)."
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "UHIHeijvcKY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define core instructions\n",
        "\n",
        "State is a fundamental concept for a LangGraph app. A state object is passed between every node and transition in the app. Here you define a state object, `OrderState`, that holds the conversation history, a structured order, and a flag indicating if the customer has finished placing their order. For simplicity, the \"structure\" in this order is just a list of strings, but this can be expanded to any Python data structure.\n",
        "\n",
        "In Python, the LangGraph state object is a Python [dictionary](https://docs.python.org/3/library/stdtypes.html#dict). You can provide a schema for this dictionary by defining it as a [`TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict).\n",
        "\n",
        "Here you also define the system instruction that the Gemini model will use. You can capture tone and style here, as well as the playbook under which the chatbot should operate."
      ],
      "metadata": {
        "id": "IGShelaFLKP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class OrderState(TypedDict):\n",
        "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
        "\n",
        "    # The chat conversation. This preserves the conversation history\n",
        "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
        "    # that state is updated by appending returned messages, not replacing\n",
        "    # them.\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    # The customer's in-progress order.\n",
        "    order: list[str]\n",
        "\n",
        "    # Flag indicating that the order is placed and completed.\n",
        "    finished: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes\n",
        "# rules for when to call different functions, as well as rules for the conversation, such\n",
        "# as tone and what is permitted for discussion.\n",
        "BARISTABOT_SYSINT = (\n",
        "    \"system\",  # 'system' indicates the message is a system instruction.\n",
        "    \"You are a BaristaBot, an interactive cafe ordering system. A human will talk to you about the \"\n",
        "    \"available products you have and you will answer any questions about menu items (and only about \"\n",
        "    \"menu items - no off-topic discussion, but you can chat about the products and their history). \"\n",
        "    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n",
        "    \"and send to the ordering system after confirming the order with the human. \"\n",
        "    \"\\n\\n\"\n",
        "    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n",
        "    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n",
        "    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n",
        "    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n",
        "    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n",
        "    \"If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect. \"\n",
        "    \"You only have the modifiers listed on the menu. \"\n",
        "    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n",
        "    \"any necessary updates and then call place_order. Once place_order has returned, thank the user and \"\n",
        "    \"say goodbye!\"\n",
        "    \"\\n\\n\"\n",
        "    \"If any of the tools are unavailable, you can break the fourth wall and tell the user that \"\n",
        "    \"they have not implemented them yet and should keep reading to do so.\",\n",
        ")\n",
        "\n",
        "# This is the message with which the system opens the conversation.\n",
        "WELCOME_MSG = \"Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\""
      ],
      "metadata": {
        "id": "2RJQRlfVjqkJ",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:21:48.104982Z",
          "iopub.execute_input": "2025-04-03T03:21:48.106371Z",
          "iopub.status.idle": "2025-04-03T03:21:49.430043Z",
          "shell.execute_reply.started": "2025-04-03T03:21:48.106308Z",
          "shell.execute_reply": "2025-04-03T03:21:49.428868Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a single turn chatboot\n",
        "\n",
        "To illustrate how LangGraph works, the following program defines a chatbot node that will execute a single turn in a chat conversation using the instructions supplied.\n",
        "\n",
        "Each node in the graph operates on the state object. The state (a Python dictionary) is passed as a parameter into the node (a function) and the new state is returned. This can be restated as pseudo-code, where `state = node(state)`.\n",
        "\n",
        "Note: For the `chatbot` node, the state is updated by *adding* the new conversation message. The `add_messages` annotation on `OrderState.messages` indicates that messages are *appended* when returned from a node. Typically state is updated by replacement, but this annotation causes `messages` to behave differently."
      ],
      "metadata": {
        "id": "PHkDsSI_NUp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Try using different models. The Gemini 2.0 flash model is highly\n",
        "# capable, great with tools, and has a generous free tier. If you\n",
        "# try the older 1.5 models, note that the `pro` models are better at\n",
        "# complex multi-tool cases like this, but the `flash` models are\n",
        "# faster and have more free quota.\n",
        "# Check out the features and quota differences here:\n",
        "#  - https://ai.google.dev/gemini-api/docs/models/gemini\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "\n",
        "\n",
        "def chatbot(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n",
        "    message_history = [BARISTABOT_SYSINT] + state[\"messages\"]\n",
        "    return {\"messages\": [llm.invoke(message_history)]}\n",
        "\n",
        "\n",
        "# Set up the initial graph based on our state definition.\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the chatbot function to the app graph as a node called \"chatbot\".\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Define the chatbot node as the app entrypoint.\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "Y359hoepjv6i",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:21:52.32815Z",
          "iopub.execute_input": "2025-04-03T03:21:52.328703Z",
          "iopub.status.idle": "2025-04-03T03:21:53.460259Z",
          "shell.execute_reply.started": "2025-04-03T03:21:52.328666Z",
          "shell.execute_reply": "2025-04-03T03:21:53.459107Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be helpful to visualise the graph you just defined. The following code renders the graph."
      ],
      "metadata": {
        "id": "T796a7eMJIjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "Image(chat_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "JP4vPWb1kPhG",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:21:53.545009Z",
          "iopub.execute_input": "2025-04-03T03:21:53.546402Z",
          "iopub.status.idle": "2025-04-03T03:21:53.653545Z",
          "shell.execute_reply.started": "2025-04-03T03:21:53.546355Z",
          "shell.execute_reply": "2025-04-03T03:21:53.652332Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "59c6e9c0-3b8a-4cc9-809f-ce2148d0c924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the graph is defined, you can run it. It only has one node, and one transition into that node, so it will transition from `__start__` to `chatbot`, execute the `chatbot` node, and terminate.\n",
        "\n",
        "To run the graph, you call `invoke` and pass an initial state object. In this case it begins with the user's initial message."
      ],
      "metadata": {
        "id": "SZtG6b8vJTSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "user_msg = \"Hello, what can you do?\"\n",
        "state = chat_graph.invoke({\"messages\": [user_msg]})\n",
        "\n",
        "# The state object contains lots of information. Uncomment the pprint lines to see it all.\n",
        "# pprint(state)\n",
        "\n",
        "# Note that the final state now has 2 messages. Our HumanMessage, and an additional AIMessage.\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content}\")"
      ],
      "metadata": {
        "id": "swkexnSoO3RU",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:10.719994Z",
          "iopub.execute_input": "2025-04-03T03:22:10.720462Z",
          "iopub.status.idle": "2025-04-03T03:22:11.743171Z",
          "shell.execute_reply.started": "2025-04-03T03:22:10.720422Z",
          "shell.execute_reply": "2025-04-03T03:22:11.741917Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d4ee49-504d-447b-8fcd-5c1e09975aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage: Hello, what can you do?\n",
            "AIMessage: Hi there! I'm BaristaBot, ready to take your coffee order. I can tell you about our menu items, answer questions, and put together your perfect order. What are you in the mood for today?\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    graph = graph_builder.compile()\n",
        "    chatbot = gr.Chatbot(type=\"messages\")\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "    '''\n",
        "    msg = gr.Textbox(\n",
        "        placeholder=\"Enter your recipe request...\",\n",
        "        container=False,\n",
        "        scale=7\n",
        "    )\n",
        "\n",
        "    user_id = gr.State(None)\n",
        "    '''\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "\n",
        "        gr_state = graph.invoke(state)\n",
        "\n",
        "        for msg in state[\"messages\"]:\n",
        "            bot_message = ''\n",
        "            if(type(msg).__name__ == 'AIMessage') :\n",
        "              bot_message = (f\"{type(msg).__name__}: {msg.content}\")\n",
        "\n",
        "            if(type(msg).__name__ == 'HumanMessage') :\n",
        "              message = (f\"{type(msg).__name__}: {msg.content}\")\n",
        "\n",
        "\n",
        "            #bot_message = random.choice([\"How are you?\", \"Today is a great day\", \"I'm very hungry\"])\n",
        "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "\n",
        "        time.sleep(2)\n",
        "        chat_history1 = chat_history\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "    msg.submit(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "\n",
        "    '''\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "3m-7cYrjzXpv",
        "outputId": "7b120537-1996-4b72-a7a4-c2eff634408e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c8741e9925dab4c183.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c8741e9925dab4c183.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You could execute this in a Python loop, but for simplicity, manually invoke one more conversational turn. This second invocation takes the state from the first call and appends another user message to elicit another response from the chatbot."
      ],
      "metadata": {
        "id": "dsczQNk9PVlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#state = chat_graph.invoke({\"messages\": [user_msg]})\n",
        "user_msg2 = \"Oh great, what kinds of latte can you make?\"\n",
        "\n",
        "state[\"messages\"].append(user_msg2)\n",
        "state = chat_graph.invoke(state)\n",
        "\n",
        "# pprint(state)\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content}\")"
      ],
      "metadata": {
        "id": "OKGonO42Pe43",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:15.434942Z",
          "iopub.execute_input": "2025-04-03T03:22:15.435367Z",
          "iopub.status.idle": "2025-04-03T03:22:16.479191Z",
          "shell.execute_reply.started": "2025-04-03T03:22:15.435331Z",
          "shell.execute_reply": "2025-04-03T03:22:16.478092Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83979178-c31b-407a-e64c-59bd1c1c1b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage: Hello, what can you do?\n",
            "AIMessage: Hi there! I'm BaristaBot, ready to take your coffee order. I can tell you about our menu items, answer questions, and put together your perfect order. What are you in the mood for today?\n",
            "HumanMessage: Oh great, what kinds of latte can you make?\n",
            "AIMessage: We have a few delicious latte options! There's our classic Latte, the sweet and spicy Chai Latte, the rich and chocolatey Mocha Latte, and the creamy Caramel Latte. Want to know more about any of them?\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    graph = graph_builder.compile()\n",
        "    chatbot = gr.Chatbot(type=\"messages\")\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    gr_state = gr.State(None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    messages = [user_msg2, user_msg]\n",
        "    def respond(message, chat_history):\n",
        "        '''\n",
        "        if(gr_state):\n",
        "          gr_state[\"messages\"].append(user_msg2)\n",
        "          graph.invoke(gr_state)\n",
        "        else:\n",
        "          gr_state = graph.invoke({\"messages\": [user_msg]})\n",
        "        '''\n",
        "\n",
        "        #state = graph.invoke(state)\n",
        "        for msg in state[\"messages\"]:\n",
        "\n",
        "            bot_message = ''\n",
        "            if(type(msg).__name__ == 'AIMessage') :\n",
        "              bot_message = (f\"{type(msg).__name__}: {msg.content}\")\n",
        "              chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "\n",
        "            if(type(msg).__name__ == 'HumanMessage') :\n",
        "              message = (f\"{type(msg).__name__}: {msg.content}\")\n",
        "              chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "\n",
        "            #bot_message = random.choice([\"How are you?\", \"Today is a great day\", \"I'm very hungry\"])\n",
        "            #.append({\"role\": \"user\", \"content\": message})\n",
        "            #chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "\n",
        "        time.sleep(1)\n",
        "        #yield \"\", chat_history\n",
        "\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    '''\n",
        "\n",
        "    msg.submit(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "\n",
        "    '''\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "7nwVP5CqITfz",
        "outputId": "a0cbc0f2-d8b3-4d2e-e95d-58c02b555f80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fa4dc87aa44fd857f9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fa4dc87aa44fd857f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a human node\n",
        "\n",
        "Instead of repeatedly running the \"graph\" in a Python loop, you can use LangGraph to loop between nodes.\n",
        "\n",
        "The `human` node will display the last message from the LLM to the user, and then prompt them for their next input. Here this is done using standard Python `print` and `input` functions, but for a real cafe situation, you could render the chat to a display or audio, and accept input from a mic or on-screen keyboard.\n",
        "\n",
        "The `chatbot` node function has also been updated to include the welcome message to start the conversation."
      ],
      "metadata": {
        "id": "v4oN47R89Rx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "\n",
        "def human_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    print(\"Model:\", last_msg.content)\n",
        "\n",
        "\n",
        "\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "\n",
        "\n",
        "    # If it looks like the user is trying to quit, flag the conversation\n",
        "    # as over.\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
        "        state[\"finished\"] = True\n",
        "\n",
        "\n",
        "    return state | {\"messages\": [(\"user\", user_input)]}\n",
        "\n",
        "    #return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def chatbot_with_welcome_msg(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        # If there are messages, continue the conversation with the Gemini model.\n",
        "        new_output = llm.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
        "    else:\n",
        "        # If there are no messages, start with the welcome message.\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    return state | {\"messages\": [new_output]}\n",
        "\n",
        "\n",
        "# Start building a new graph.\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the chatbot and human nodes to the app graph.\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "\n",
        "# Start with the chatbot again.\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# The chatbot will always go to the human next.\n",
        "graph_builder.add_edge(\"chatbot\", \"human\");"
      ],
      "metadata": {
        "id": "UtOpn68ospVj",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:20.613178Z",
          "iopub.execute_input": "2025-04-03T03:22:20.613599Z",
          "iopub.status.idle": "2025-04-03T03:22:20.625365Z",
          "shell.execute_reply.started": "2025-04-03T03:22:20.613564Z",
          "shell.execute_reply": "2025-04-03T03:22:20.6241Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 102
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you can run this, note that if you added an edge from `human` back to `chatbot`, the graph will cycle forever as there is no exit condition. One way to break the cycle is to add a check for a human input like `q` or `quit` and use that to break the loop.\n",
        "\n",
        "In LangGraph, this is achieved with a conditional edge. This is similar to a regular graph transition, except a custom function is called to determine which edge to traverse.\n",
        "\n",
        "Conditional edge functions take the state as input, and return a string representing the name of the node to which it will transition."
      ],
      "metadata": {
        "id": "SWXwd1ITUSPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "    if state.get(\"finished\", False):\n",
        "        return END\n",
        "    else:\n",
        "        return \"chatbot\"\n",
        "\n",
        "\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "chat_with_human_graph = graph_builder.compile()\n",
        "\n",
        "Image(chat_with_human_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "6468OAgSU2He",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:23.600317Z",
          "iopub.execute_input": "2025-04-03T03:22:23.600697Z",
          "iopub.status.idle": "2025-04-03T03:22:23.675087Z",
          "shell.execute_reply.started": "2025-04-03T03:22:23.600656Z",
          "shell.execute_reply": "2025-04-03T03:22:23.674016Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "25defe93-b695-437c-ae8d-17540dc4d9fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "execution_count": 103
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this new graph to see how the interaction loop is now captured within the graph. Input `quit` to exit the program.\n",
        "\n",
        "**You must uncomment the `.invoke(...)` line to run this step.**"
      ],
      "metadata": {
        "id": "yrQI6-3FS_op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The default recursion limit for traversing nodes is 25 - setting it higher means\n",
        "# you can try a more complex order with multiple steps and round-trips (and you\n",
        "# can chat for longer!)\n",
        "config = {\"recursion_limit\": 100}\n",
        "\n",
        "# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n",
        "# other exit terms defined in `human_node`.\n",
        "# Uncomment this line to execute the graph:\n",
        "state = chat_with_human_graph.invoke({\"messages\": []}, config)\n",
        "\n",
        "# Things to try:\n",
        "#  - Just chat! There's no ordering or menu yet.\n",
        "#  - 'q' to exit.\n",
        "\n",
        "# pprint(state)"
      ],
      "metadata": {
        "id": "udGNmyasTGJG",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:30.34216Z",
          "iopub.execute_input": "2025-04-03T03:22:30.34259Z",
          "iopub.status.idle": "2025-04-03T03:22:39.806014Z",
          "shell.execute_reply.started": "2025-04-03T03:22:30.342553Z",
          "shell.execute_reply": "2025-04-03T03:22:39.804784Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2549a9eb-5141-4ecb-bb8c-69bc943f9c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n",
            "User: hi\n",
            "Model: Hi there! What can I get for you today?\n",
            "User: hello\n",
            "Model: Hi! What would you like to order?\n",
            "User: Water\n",
            "Model: ```tool_code\n",
            "add_to_order(item='Water', quantity=1)\n",
            "```\n",
            "User: q\n"
          ]
        }
      ],
      "execution_count": 104
    },
    {
      "cell_type": "code",
      "source": [
        "class OrderStateGr(TypedDict):\n",
        "    recipe_request: str\n",
        "    recipe: str\n",
        "    allergenes: str\n",
        "    allergenes_detected: bool\n",
        "    human_feedback: str\n",
        "    final_recipe: str\n",
        "    # The chat conversation. This preserves the conversation history\n",
        "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
        "    # that state is updated by appending returned messages, not replacing\n",
        "    # them.\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    # The customer's in-progress order.\n",
        "    order: list[str]\n",
        "\n",
        "    # Flag indicating that the order is placed and completed.\n",
        "    finished: bool"
      ],
      "metadata": {
        "id": "vmzv5SbdQ7v7"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_exit_human_node_gr(state: OrderStateGr) -> Literal[\"chatbot\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "    if state.get(\"finished\", False):\n",
        "        return END\n",
        "    else:\n",
        "        return \"chatbot\""
      ],
      "metadata": {
        "id": "OVv03sRwQe4b"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_feedback_handler(state: OrderStateGr) -> OrderStateGr:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    print(\"Model:\", last_msg.content)\n",
        "\n",
        "\n",
        "\n",
        "    #user_input = input(\"User: \")\n",
        "    user_input = \"What are you selling?\"\n",
        "\n",
        "\n",
        "\n",
        "    # If it looks like the user is trying to quit, flag the conversation\n",
        "    # as over.\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
        "        state[\"finished\"] = True\n",
        "\n",
        "\n",
        "    return state | {\"messages\": [(\"user\", user_input)]}"
      ],
      "metadata": {
        "id": "p_h2TBkcQc48"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_with_welcome_msg_gr(state: OrderStateGr) -> OrderStateGr:\n",
        "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        # If there are messages, continue the conversation with the Gemini model.\n",
        "        #new_output = llm.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
        "        response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the recipe for chocolate cookie?\"\n",
        "        }]\n",
        "       )\n",
        "        state[\"messages\"] = response.choices[0].message.content\n",
        "        new_output = response.choices[0].message.content\n",
        "    else:\n",
        "        # If there are no messages, start with the welcome message.\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "    #state['messages'].append(\"chatbot called\")\n",
        "\n",
        "    return state | {\"messages\": [new_output]}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "h59GCzXqflzZ"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start building a new graph.\n",
        "graph_builder_gr = StateGraph(OrderStateGr)\n",
        "\n",
        "# Add the chatbot and human nodes to the app graph.\n",
        "graph_builder_gr.add_node(\"chatbot\", chatbot_with_welcome_msg_gr)\n",
        "graph_builder_gr.add_node(\"human_feedback_handler\", human_feedback_handler)\n",
        "\n",
        "# Start with the chatbot again.\n",
        "graph_builder_gr.add_edge(START, \"chatbot\")\n",
        "\n",
        "# The chatbot will always go to the human next.\n",
        "graph_builder_gr.add_edge(\"chatbot\", \"human_feedback_handler\");\n",
        "\n",
        "graph_builder_gr.add_conditional_edges(\"human_feedback_handler\", maybe_exit_human_node_gr)\n",
        "chat_with_human_graph_gr = graph_builder_gr.compile()\n",
        "Image(chat_with_human_graph_gr.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "hAVIDk9bVTgl",
        "outputId": "986ad0bf-8f12-40f8-c3e6-39687f5042dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_gr = chat_with_human_graph_gr.invoke({\"messages\": []}, config)"
      ],
      "metadata": {
        "id": "2d3u_3gDZ7Bi",
        "outputId": "680d5a26-1f58-43ed-ec04-ff120145f158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n",
            "Model: Ingredients for Chocolate Cookies:\n",
            "\n",
            "- 1 cup unsalted butter, at room temperature\n",
            "- 1 and 1/2 cup granulated white sugar\n",
            "- 2 large eggs\n",
            "- 2 teaspoons pure vanilla extract\n",
            "- 3/4 cup unsweetened cocoa powder\n",
            "- 2 cups all-purpose flour\n",
            "- 1 teaspoon baking soda\n",
            "- 1/2 teaspoon baking powder\n",
            "- 1/2 teaspoon salt\n",
            "- 2 cups chocolate chips or chunks\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. Preheat the oven to 350 degrees F (180 degrees C) and line two baking trays with parchment paper.\n",
            "2. In a large mixing bowl, cream together the butter and sugar until light and fluffy. This will take about 2-3 minutes using an electric mixer.\n",
            "3. Add the eggs, one at a time, followed by the vanilla extract, beating well after each addition.\n",
            "4. Sift in the cocoa powder and mix until well combined.\n",
            "5. In a separate bowl, combine the flour, baking soda, baking powder, and salt.\n",
            "6. Gradually add the dry ingredients to the butter mixture, mixing just until combined. Don't overmix!\n",
            "7. Stir in the chocolate chips or chunks.\n",
            "8. Drop tablespoonfuls of dough onto the prepared baking trays, spacing them about 2 inches apart.\n",
            "9. Bake in the preheated oven for 10-12 minutes, or until the edges are set but the centers are still soft. They'll firm up as they cool.\n",
            "10. Allow cookies to cool on the baking trays for 5 minutes, then transfer them to wire racks to cool completely.\n",
            "\n",
            "Enjoy your delicious homemade chocolate cookies!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-288-af444e73dcf9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_gr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_human_graph_gr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2683\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2684\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2329\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2332\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 )\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-285-459cfd973d53>\u001b[0m in \u001b[0;36mchatbot_with_welcome_msg_gr\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# If there are messages, continue the conversation with the Gemini model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#new_output = llm.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         response = openai_client.chat.completions.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         messages=[{\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    970\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    memory = MemorySaver()\n",
        "    graph = graph_builder_gr.compile(checkpointer=memory,\n",
        "        interrupt_before=[\"human_feedback_handler\"])\n",
        "    chatbot = gr.Chatbot(type=\"messages\")\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    user_id = gr.State(None)\n",
        "    gr_state = gr.State(None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def respond(message, chat_history, gr_state, user_id):\n",
        "        config = {\"configurable\": {\"thread_id\": user_id}}\n",
        "\n",
        "        if not gr_state:\n",
        "\n",
        "           #message = (f\"{type(message).__name__}: {message.content}\")\n",
        "           chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "           bot_message = WELCOME_MSG\n",
        "           chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "           gr_state = {\"messages\": [message]}\n",
        "\n",
        "\n",
        "           #return \"\", chat_history\n",
        "           yield chat_history, gr_state, user_id, None\n",
        "        else:\n",
        "          #gr_state = graph.get_state().values\n",
        "          gr_state['messages'].append(message)\n",
        "          graph.update_state(config=config,values=gr_state)\n",
        "          lst_msg = gr_state['messages'][-1]\n",
        "          bot_message = lst_msg\n",
        "          chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "\n",
        "          #message = (f\"{type(message).__name__}: {message.content}\")\n",
        "          chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "          #return \"\", chat_history\n",
        "\n",
        "\n",
        "          gr_state['messages'].append(message)\n",
        "          graph.update_state(config=config,values=gr_state)\n",
        "\n",
        "          yield chat_history, gr_state, user_id, None\n",
        "\n",
        "\n",
        "       # Process through graph\n",
        "        for event in graph.stream(None if \"human_feedback\" in state else state, config=config):\n",
        "            chat_history.append({\"role\": \"assistant\", \"content\": \"Chatbot message\"})\n",
        "            gr_state = graph.get_state(config=config).values\n",
        "            if isinstance(event, dict):\n",
        "              chat_history.append({\"role\": \"assistant\", \"content\": \"Chatbot message\"})\n",
        "\n",
        "            yield chat_history, gr_state, user_id, None\n",
        "\n",
        "      #msg.submit(respond, [msg, chatbot, gr_state], [msg, chatbot])\n",
        "\n",
        "\n",
        "\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, gr_state, user_id],\n",
        "        outputs=[chatbot, gr_state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "frY2CysVWKpJ",
        "outputId": "a34cdc19-6ca5-44ee-84d7-3fe0eb3d92a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3e4e5c6e8be4a42687.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3e4e5c6e8be4a42687.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a \"live\" menu\n",
        "\n",
        "BaristaBot currently has no awareness of the available items at the cafe, so it will hallucinate a menu. One option would be to hard-code a menu into the system prompt. This would work well, but to simulate a system where the menu is more dynamic and could respond to fluctuating stock levels, you will put the menu into a custom tool.\n",
        "\n",
        "There are two types of tools that this system will use. Stateless tools that can be run automatically, and stateful tools that modify the order. The \"get current menu\" tool is stateless, in that it does not make any changes to the live order, so it can be called automatically.\n",
        "\n",
        "In a LangGraph app, you can annotate Python functions as tools by applying the `@tools` annotation.\n",
        "\n"
      ],
      "metadata": {
        "id": "iwDFpJreW66e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_menu() -> str:\n",
        "    \"\"\"Provide the latest up-to-date menu.\"\"\"\n",
        "    # Note that this is just hard-coded text, but you could connect this to a live stock\n",
        "    # database, or you could use Gemini's multi-modal capabilities and take live photos of\n",
        "    # your cafe's chalk menu or the products on the counter and assmble them into an input.\n",
        "\n",
        "    return \"\"\"\n",
        "    MENU:\n",
        "    Coffee Drinks:\n",
        "    Espresso\n",
        "    Americano\n",
        "    Cold Brew\n",
        "\n",
        "    Coffee Drinks with Milk:\n",
        "    Latte\n",
        "    Cappuccino\n",
        "    Cortado\n",
        "    Macchiato\n",
        "    Mocha\n",
        "    Flat White\n",
        "\n",
        "    Tea Drinks:\n",
        "    English Breakfast Tea\n",
        "    Green Tea\n",
        "    Earl Grey\n",
        "\n",
        "    Tea Drinks with Milk:\n",
        "    Chai Latte\n",
        "    Matcha Latte\n",
        "    London Fog\n",
        "\n",
        "    Other Drinks:\n",
        "    Steamer\n",
        "    Hot Chocolate\n",
        "\n",
        "    Modifiers:\n",
        "    Milk options: Whole, 2%, Oat, Almond, 2% Lactose Free; Default option: whole\n",
        "    Espresso shots: Single, Double, Triple, Quadruple; default: Double\n",
        "    Caffeine: Decaf, Regular; default: Regular\n",
        "    Hot-Iced: Hot, Iced; Default: Hot\n",
        "    Sweeteners (option to add one or more): vanilla sweetener, hazelnut sweetener, caramel sauce, chocolate sauce, sugar free vanilla sweetener\n",
        "    Special requests: any reasonable modification that does not involve items not on the menu, for example: 'extra hot', 'one pump', 'half caff', 'extra foam', etc.\n",
        "\n",
        "    \"dirty\" means add a shot of espresso to a drink that doesn't usually have it, like \"Dirty Chai Latte\".\n",
        "    \"Regular milk\" is the same as 'whole milk'.\n",
        "    \"Sweetened\" means add some regular sugar, not a sweetener.\n",
        "\n",
        "    Soy milk has run out of stock today, so soy is not available.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "hG1n6mNFHsYW",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:45.416893Z",
          "iopub.execute_input": "2025-04-03T03:22:45.417431Z",
          "iopub.status.idle": "2025-04-03T03:22:45.431725Z",
          "shell.execute_reply.started": "2025-04-03T03:22:45.417374Z",
          "shell.execute_reply": "2025-04-03T03:22:45.430324Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now add the new tool to the graph. The `get_menu` tool is wrapped in a [`ToolNode`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) that handles calling the tool and passing the response as a message through the graph. The tools are also bound to the `llm` object so that the underlying model knows they exist. As you now have a different `llm` object to invoke, you need to update the `chatbot` node so that it is aware of the tools.\n"
      ],
      "metadata": {
        "id": "W82wDfAH-RMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Define the tools and create a \"tools\" node.\n",
        "tools = [get_menu]\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "# Attach the tools to the model so that it knows what it can call.\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def maybe_route_to_tools(state: OrderState) -> Literal[\"tools\", \"human\"]:\n",
        "    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n",
        "    if not (msgs := state.get(\"messages\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    # Only route based on the last message.\n",
        "    msg = msgs[-1]\n",
        "\n",
        "    # When the chatbot returns tool_calls, route to the \"tools\" node.\n",
        "    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        return \"human\"\n",
        "\n",
        "\n",
        "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n",
        "    defaults = {\"order\": [], \"finished\": False}\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        new_output = llm_with_tools.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
        "    else:\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    # Set up some defaults if not already set, then pass through the provided state,\n",
        "    # overriding only the \"messages\" field.\n",
        "    return defaults | state | {\"messages\": [new_output]}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the nodes, including the new tool_node.\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Chatbot may go to tools, or human.\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "# Human may go back to chatbot, or exit.\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "# Tools always route back to chat afterwards.\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_with_menu = graph_builder.compile()\n",
        "\n",
        "Image(graph_with_menu.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "KJVZGC2TlKqj",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:49.660236Z",
          "iopub.execute_input": "2025-04-03T03:22:49.660632Z",
          "iopub.status.idle": "2025-04-03T03:22:49.759324Z",
          "shell.execute_reply.started": "2025-04-03T03:22:49.660597Z",
          "shell.execute_reply": "2025-04-03T03:22:49.758101Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "36b0996f-9e4b-43a6-97a0-e61ea54c6b5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run the new graph to see how the model uses the menu.\n",
        "\n",
        "**You must uncomment the `.invoke(...)` line to run this step.**"
      ],
      "metadata": {
        "id": "kbFdxxWdauzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember that you have not implemented ordering yet, so this will loop forever,\n",
        "# unless you input `q`, `quit` or one of the other exit terms defined in the\n",
        "# `human_node`.\n",
        "# Uncomment this line to execute the graph:\n",
        "state = graph_with_menu.invoke({\"messages\": []}, config)\n",
        "\n",
        "# Things to try:\n",
        "# - I'd love an espresso drink, what have you got?\n",
        "# - What teas do you have?\n",
        "# - Can you do a long black? (this is on the menu as an \"Americano\" - see if it can\n",
        "#   figure it out)\n",
        "# - 'q' to exit.\n",
        "\n",
        "\n",
        "# pprint(state)"
      ],
      "metadata": {
        "id": "wcsVkMAApBGu",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:22:56.997801Z",
          "iopub.execute_input": "2025-04-03T03:22:56.998267Z",
          "iopub.status.idle": "2025-04-03T03:23:20.462404Z",
          "shell.execute_reply.started": "2025-04-03T03:22:56.998226Z",
          "shell.execute_reply": "2025-04-03T03:23:20.461172Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b118dde8-91ef-4627-f4a9-735c66b885e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n",
            "User: q\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle orders\n",
        "\n",
        "To build up an order during the chat conversation, you will need to update the state to track the order, and provide simple tools that update this state. These need to be explicit as the model should not directly have access to the apps internal state, or it risks being manipulated arbitrarily.\n",
        "\n",
        "The ordering tools will be added as stubs in a separate node so that you can edit the state directly. Using the `@tool` annotation is still a handy way to define their schema, so the ordering tools below are implemented as empty Python functions."
      ],
      "metadata": {
        "id": "ikO4M2fZDkyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "from random import randint\n",
        "\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "\n",
        "# These functions have no body; LangGraph does not allow @tools to update\n",
        "# the conversation state, so you will implement a separate node to handle\n",
        "# state updates. Using @tools is still very convenient for defining the tool\n",
        "# schema, so empty functions have been defined that will be bound to the LLM\n",
        "# but their implementation is deferred to the order_node.\n",
        "\n",
        "\n",
        "@tool\n",
        "def add_to_order(drink: str, modifiers: Iterable[str]) -> str:\n",
        "    \"\"\"Adds the specified drink to the customer's order, including any modifiers.\n",
        "\n",
        "    Returns:\n",
        "      The updated order in progress.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def confirm_order() -> str:\n",
        "    \"\"\"Asks the customer if the order is correct.\n",
        "\n",
        "    Returns:\n",
        "      The user's free-text response.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_order() -> str:\n",
        "    \"\"\"Returns the users order so far. One item per line.\"\"\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def clear_order():\n",
        "    \"\"\"Removes all items from the user's order.\"\"\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def place_order() -> int:\n",
        "    \"\"\"Sends the order to the barista for fulfillment.\n",
        "\n",
        "    Returns:\n",
        "      The estimated number of minutes until the order is ready.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def order_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"The ordering node. This is where the order state is manipulated.\"\"\"\n",
        "    tool_msg = state.get(\"messages\", [])[-1]\n",
        "    order = state.get(\"order\", [])\n",
        "    outbound_msgs = []\n",
        "    order_placed = False\n",
        "\n",
        "    for tool_call in tool_msg.tool_calls:\n",
        "\n",
        "        if tool_call[\"name\"] == \"add_to_order\":\n",
        "\n",
        "            # Each order item is just a string. This is where it assembled as \"drink (modifiers, ...)\".\n",
        "            modifiers = tool_call[\"args\"][\"modifiers\"]\n",
        "            modifier_str = \", \".join(modifiers) if modifiers else \"no modifiers\"\n",
        "\n",
        "            order.append(f'{tool_call[\"args\"][\"drink\"]} ({modifier_str})')\n",
        "            response = \"\\n\".join(order)\n",
        "\n",
        "        elif tool_call[\"name\"] == \"confirm_order\":\n",
        "\n",
        "            # We could entrust the LLM to do order confirmation, but it is a good practice to\n",
        "            # show the user the exact data that comprises their order so that what they confirm\n",
        "            # precisely matches the order that goes to the kitchen - avoiding hallucination\n",
        "            # or reality skew.\n",
        "\n",
        "            # In a real scenario, this is where you would connect your POS screen to show the\n",
        "            # order to the user.\n",
        "\n",
        "            print(\"Your order:\")\n",
        "            if not order:\n",
        "                print(\"  (no items)\")\n",
        "\n",
        "            for drink in order:\n",
        "                print(f\"  {drink}\")\n",
        "\n",
        "            response = input(\"Is this correct? \")\n",
        "\n",
        "        elif tool_call[\"name\"] == \"get_order\":\n",
        "\n",
        "            response = \"\\n\".join(order) if order else \"(no order)\"\n",
        "\n",
        "        elif tool_call[\"name\"] == \"clear_order\":\n",
        "\n",
        "            order.clear()\n",
        "            response = None\n",
        "\n",
        "        elif tool_call[\"name\"] == \"place_order\":\n",
        "\n",
        "            order_text = \"\\n\".join(order)\n",
        "            print(\"Sending order to kitchen!\")\n",
        "            print(order_text)\n",
        "\n",
        "            # TODO(you!): Implement cafe.\n",
        "            order_placed = True\n",
        "            response = randint(1, 5)  # ETA in minutes\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n",
        "\n",
        "        # Record the tool results as tool messages.\n",
        "        outbound_msgs.append(\n",
        "            ToolMessage(\n",
        "                content=response,\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return {\"messages\": outbound_msgs, \"order\": order, \"finished\": order_placed}\n",
        "\n",
        "\n",
        "def maybe_route_to_tools(state: OrderState) -> str:\n",
        "    \"\"\"Route between chat and tool nodes if a tool call is made.\"\"\"\n",
        "    if not (msgs := state.get(\"messages\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    msg = msgs[-1]\n",
        "\n",
        "    if state.get(\"finished\", False):\n",
        "        # When an order is placed, exit the app. The system instruction indicates\n",
        "        # that the chatbot should say thanks and goodbye at this point, so we can exit\n",
        "        # cleanly.\n",
        "        return END\n",
        "\n",
        "    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "        # Route to `tools` node for any automated tool calls first.\n",
        "        if any(\n",
        "            tool[\"name\"] in tool_node.tools_by_name.keys() for tool in msg.tool_calls\n",
        "        ):\n",
        "            return \"tools\"\n",
        "        else:\n",
        "            return \"ordering\"\n",
        "\n",
        "    else:\n",
        "        return \"human\""
      ],
      "metadata": {
        "id": "jqsLovPBQe0I",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:23:27.310253Z",
          "iopub.execute_input": "2025-04-03T03:23:27.310672Z",
          "iopub.status.idle": "2025-04-03T03:23:27.346944Z",
          "shell.execute_reply.started": "2025-04-03T03:23:27.310635Z",
          "shell.execute_reply": "2025-04-03T03:23:27.345751Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the graph. The LLM needs to know about the tools too, so that it can invoke them. Here you set up 2 sets of tools corresponding to the nodes under which they operate: automated and ordering."
      ],
      "metadata": {
        "id": "UzfKW3lkxtS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-tools will be invoked automatically by the ToolNode\n",
        "auto_tools = [get_menu]\n",
        "tool_node = ToolNode(auto_tools)\n",
        "\n",
        "# Order-tools will be handled by the order node.\n",
        "order_tools = [add_to_order, confirm_order, get_order, clear_order, place_order]\n",
        "\n",
        "# The LLM needs to know about all of the tools, so specify everything here.\n",
        "llm_with_tools = llm.bind_tools(auto_tools + order_tools)\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Nodes\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"ordering\", order_node)\n",
        "\n",
        "# Chatbot -> {ordering, tools, human, END}\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "# Human -> {chatbot, END}\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "# Tools (both kinds) always route back to chat afterwards.\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"ordering\", \"chatbot\")\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_with_order_tools = graph_builder.compile()\n",
        "\n",
        "Image(graph_with_order_tools.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "9rqkQzlZxrzp",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:23:30.934271Z",
          "iopub.execute_input": "2025-04-03T03:23:30.934724Z",
          "iopub.status.idle": "2025-04-03T03:23:31.061548Z",
          "shell.execute_reply.started": "2025-04-03T03:23:30.934683Z",
          "shell.execute_reply": "2025-04-03T03:23:31.060287Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "4107c4c0-5ff4-442c-a4a8-4aa176506f10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run the complete ordering system graph.\n",
        "\n",
        "**You must uncomment the `.invoke(...)` line to run this step.**"
      ],
      "metadata": {
        "id": "G0SVsDu4gD_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this line to execute the graph:\n",
        "state = graph_with_order_tools.invoke({\"messages\": []}, config)\n",
        "\n",
        "# Things to try:\n",
        "# - Order a drink!\n",
        "# - Make a change to your order.\n",
        "# - \"Which teas are from England?\"\n",
        "# - Note that the graph should naturally exit after placing an order.\n",
        "\n",
        "# pprint(state)"
      ],
      "metadata": {
        "id": "NCRSgaBUfIHF",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:23:38.175937Z",
          "iopub.execute_input": "2025-04-03T03:23:38.176336Z",
          "iopub.status.idle": "2025-04-03T03:24:17.03696Z",
          "shell.execute_reply.started": "2025-04-03T03:23:38.176303Z",
          "shell.execute_reply": "2025-04-03T03:24:17.035721Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a99a81-d1ff-49ee-c978-ba6418bb8b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n",
            "User: q\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The order state has been captured both in the `place_order` function and in the final conversational state returned from executing the graph. This iillustrates how you can integrate your own systems to a graph app, as well as collect the final results of executing such an app."
      ],
      "metadata": {
        "id": "8KM4-akgEVSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this once you have run the graph from the previous cell.\n",
        "pprint(state[\"order\"])"
      ],
      "metadata": {
        "id": "n4jUJCr3fJpy",
        "execution": {
          "iopub.status.busy": "2025-04-03T03:24:23.482128Z",
          "iopub.execute_input": "2025-04-03T03:24:23.482492Z",
          "iopub.status.idle": "2025-04-03T03:24:23.488201Z",
          "shell.execute_reply.started": "2025-04-03T03:24:23.482458Z",
          "shell.execute_reply": "2025-04-03T03:24:23.486912Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bcb0b10-a3ad-4e01-b4e5-a2fae01aadf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further exercises\n",
        "\n",
        "Congratulations on building an agentic, human-in-the-loop, natural-language powered cafe ordering system using LangGraph and the Gemini API!\n",
        "\n",
        "This example app could be taken in many different directions. You should try and build out your own ideas, but for some inspiration, consider:\n",
        "\n",
        "* Adding more structure the order (`OrderState.order`) - e.g. separate fields for item, modifiers and even quantity.\n",
        "* Currently the model can only clear and re-add items, so add a function to `remove_item`s from the order.\n",
        "* Try building a UI that displays the in-progress order and hosts the chat. Frameworks like [Gradio](https://www.gradio.app/) or [Mesop](https://google.github.io/mesop/) are great for this.\n",
        "\n",
        "This system works well for a single person ordering, but agentic systems can interact with many sources. For a big stretch exercise, try and extend this app to run at a specific schedule, and contact your friends or colleagues over [Chat](https://developers.google.com/workspace/chat/api/reference/rest) to collect their daily coffee orders.\n",
        "\n",
        "*- [Mark McD](https://linktr.ee/markmcd)*"
      ],
      "metadata": {
        "id": "1BV4euQjRR4w",
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHEiL9yqlSv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradio Integration**"
      ],
      "metadata": {
        "id": "6_974V0plXKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "id": "oWup5fI2ocbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import gradio as gr\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "KH2G_BUIlnOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "with gr.Blocks() as demo:\n",
        "    graph = graph_builder.compile(\n",
        "    )\n",
        "    chatbot = gr.Chatbot(type=\"messages\")\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        graph_with_order_tools({\"messages\": []}, config)\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "A6bPpDiVtl0M",
        "outputId": "f44e2268-e324-41ba-dde3-af6c4346ee64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e8f8d66bff991aa4af.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e8f8d66bff991aa4af.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    recipe_request: str\n",
        "    recipe: str\n",
        "    allergenes: str\n",
        "    allergenes_detected: bool\n",
        "    human_feedback: str\n",
        "    final_recipe: str"
      ],
      "metadata": {
        "id": "4gq1ZO5PoU0-"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize graph builder\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "TvTNut1ClQKJ"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe_generator(state: State) -> State:\n",
        "    \"\"\"Generate initial recipe based on request\"\"\"\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Generate a detailed recipe for: {state['recipe_request']}\"\n",
        "        }]\n",
        "    )\n",
        "    state[\"recipe\"] = response.choices[0].message.content\n",
        "\n",
        "    # Check for common allergenes\n",
        "    allergenes_check = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Analyze this recipe for common allergenes (nuts, dairy, gluten, shellfish, eggs). Only respond with 'ALLERGENES FOUND' plus the allergenes detected or 'NO ALLERGENES': {state['recipe']}\"\n",
        "        }]\n",
        "    )\n",
        "    state[\"allergenes\"] = allergenes_check.choices[0].message.content.split(\"ALLERGENES FOUND\")[1].strip()\n",
        "    state[\"allergenes_detected\"] = \"ALLERGENES FOUND\" in allergenes_check.choices[0].message.content\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "dU1HFi0apeKc"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_feedback_handler(state: State) -> State:\n",
        "    \"\"\"Handle human feedback for allergenes\"\"\"\n",
        "    state[\"allergenes_detected\"] = False\n",
        "    return state"
      ],
      "metadata": {
        "id": "ANLMEkKqpnzr"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe_finalizer(state: State) -> State:\n",
        "    \"\"\"Finalize recipe based on feedback if any\"\"\"\n",
        "    if \"human_feedback\" in state and state[\"human_feedback\"]:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Modify this recipe according to dietary restrictions: {state['recipe']}\\nRestrictions: {state['human_feedback']}. Always return the full recipe, even if no changes are needed.\"\n",
        "            }]\n",
        "        )\n",
        "        state[\"final_recipe\"] = response.choices[0].message.content\n",
        "    else:\n",
        "        state[\"final_recipe\"] = state[\"recipe\"]\n",
        "    return state"
      ],
      "metadata": {
        "id": "Yhp4HXLRprRD"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def allergenes_check_condition(state: State) -> str:\n",
        "    \"\"\"Determine next step based on allergenes detection\"\"\"\n",
        "    if state[\"allergenes_detected\"]:\n",
        "        return \"human_feedback_handler\"\n",
        "    else:\n",
        "        return \"recipe_finalizer\""
      ],
      "metadata": {
        "id": "snALXj7opxhX"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add nodes\n",
        "graph_builder.add_node(\"recipe_generator\", recipe_generator)\n",
        "graph_builder.add_node(\"human_feedback_handler\", human_feedback_handler)\n",
        "graph_builder.add_node(\"recipe_finalizer\", recipe_finalizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUV372elp1Lh",
        "outputId": "d470ea24-a82b-4e2e-d15d-ab6fb1254f2a"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c2362b10c10>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add edges\n",
        "graph_builder.add_edge(START, \"recipe_generator\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"recipe_generator\",\n",
        "    allergenes_check_condition,\n",
        "    {\n",
        "        \"human_feedback_handler\": \"human_feedback_handler\",\n",
        "        \"recipe_finalizer\": \"recipe_finalizer\"\n",
        "    }\n",
        ")\n",
        "graph_builder.add_edge(\"human_feedback_handler\", \"recipe_finalizer\")\n",
        "graph_builder.add_edge(\"recipe_finalizer\", END)\n",
        "\n",
        "Image(graph_builder.compile().get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "bOCqVfIaqBQW",
        "outputId": "258583a8-f076-4dd8-a243-553e274943b7"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "CSS = \"\"\"\n",
        ".contain { display: flex; flex-direction: column; }\n",
        "#component-0 { height: 100%; }\n",
        "#chatbot { flex-grow: 1; overflow: auto;}\n",
        "\"\"\"\n",
        "with gr.Blocks(css=CSS, title=\"🎂 SafePlates\") as demo:\n",
        "    memory = MemorySaver()\n",
        "    graph = graph_builder.compile(\n",
        "        checkpointer=memory,\n",
        "        interrupt_before=[\"human_feedback_handler\"]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🎂 SafePlates\n",
        "\n",
        "    SafePlates: A smart recipe assistant that creates personalized meals while checking for allergens to ensure safe and delicious dining.\n",
        "\n",
        "    Start by entering your recipe request in the text box below. The assistant will:\n",
        "\n",
        "    1. Generate a detailed recipe based on your request\n",
        "    2. Check for common allergens (nuts, dairy, gluten, shellfish, eggs)\n",
        "    3. If allergens are detected, ask for your dietary restrictions\n",
        "    4. Modify the recipe according to your needs\n",
        "    5. Provide you with a safe and delicious final recipe\n",
        "\n",
        "    🔗 Connect with me on [LinkedIn](https://www.linkedin.com/in/felixkemeth) and [X](https://x.com/fkemeth)\n",
        "    \"\"\")\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        show_copy_button=False,\n",
        "        show_share_button=True,\n",
        "        label=\"Recipe Assistant\",\n",
        "        elem_id=\"chatbot\",\n",
        "        type=\"tuples\"\n",
        "    )\n",
        "    msg = gr.Textbox(\n",
        "        placeholder=\"Enter your recipe request...\",\n",
        "        container=False,\n",
        "        scale=7\n",
        "    )\n",
        "    user_id = gr.State(None)\n",
        "    state = gr.State(None)\n",
        "\n",
        "    def process_request(message, history, state, user_id):\n",
        "        if not user_id:\n",
        "            user_id = str(uuid.uuid4())\n",
        "        config = {\"configurable\": {\"thread_id\": user_id}}\n",
        "\n",
        "        # Handle initial request or human feedback\n",
        "        if not state:\n",
        "            state = {\"recipe_request\": message}\n",
        "            history = [(message, \"Generating recipe...\")]\n",
        "        elif \"allergenes_detected\" in state and state[\"allergenes_detected\"]:\n",
        "            state[\"human_feedback\"] = message\n",
        "            graph.update_state(config=config, values=state)\n",
        "            history.append((message, \"Updating recipe...\"))\n",
        "        yield history, state, user_id, None\n",
        "\n",
        "        # Process through graph\n",
        "        for event in graph.stream(None if \"human_feedback\" in state else state, config=config):\n",
        "            state = graph.get_state(config=config).values\n",
        "            if isinstance(event, dict):\n",
        "                if \"recipe_generator\" in event:\n",
        "                    if event[\"recipe_generator\"][\"allergenes_detected\"]:\n",
        "                        history.append((None, f\"Are you allergic to any of the following ingredients:\\n{event['recipe_generator']['allergenes'][2:]}\\nIf so, please specify which ones.\"))\n",
        "                    else:\n",
        "                        history.append((None, event[\"recipe_generator\"][\"recipe\"]))\n",
        "                elif \"recipe_finalizer\" in event:\n",
        "                    history.append((None, f\"Here's your final recipe:\\n\\n{event['recipe_finalizer']['final_recipe']}\"))\n",
        "            yield history, state, user_id, None\n",
        "\n",
        "    msg.submit(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        example_button1 = gr.Button(\"Example 1: Lemon Cake\")\n",
        "        example_button2 = gr.Button(\"Example 2: Chocolate Cookies\")\n",
        "        example_button3 = gr.Button(\"Example 3: Banana Bread\")\n",
        "\n",
        "    def load_example(example_num):\n",
        "        if example_num == 1:\n",
        "            return \"I want a recipe for a lemon cake\"\n",
        "        elif example_num == 2:\n",
        "            return \"I want a recipe for chocolate cookies\"\n",
        "        elif example_num == 3:\n",
        "            return \"I want a recipe for banana bread\"\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    example_button1.click(fn=load_example, inputs=[gr.Number(value=1, visible=False)], outputs=[msg], show_progress=\"hidden\").then(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "    example_button2.click(fn=load_example, inputs=[gr.Number(value=2, visible=False)], outputs=[msg], show_progress=\"hidden\").then(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "    example_button3.click(fn=load_example, inputs=[gr.Number(value=3, visible=False)], outputs=[msg], show_progress=\"hidden\").then(\n",
        "        process_request,\n",
        "        inputs=[msg, chatbot, state, user_id],\n",
        "        outputs=[chatbot, state, user_id, msg],\n",
        "        show_progress=\"hidden\"\n",
        "    )\n",
        "\n",
        "    refresh_button = gr.Button(\"🔄 Refresh\")\n",
        "    refresh_button.click(fn=lambda: None, inputs=[], outputs=[chatbot, state, user_id], js=\"() => {window.location.reload()}\")\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        By using this application, you agree to OpenAI's [terms of use](https://openai.com/policies/row-terms-of-use/) and [privacy policy](https://openai.com/policies/row-privacy-policy/).\n",
        "        \"\"\"\n",
        "    )\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "tKjDktUCqmKq",
        "outputId": "760dc4af-d8c0-44ce-8ebf-764ca8d472e4"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-203-191e2e77a782>:30: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d9a8c2b7484485010f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d9a8c2b7484485010f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    }
  ]
}